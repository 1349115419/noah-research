{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "The architecture utilises the ideas of:<br>\n",
    "Khamis, Sameh, et al. (Google / PerceptiveIO) \"Stereonet: Guided hierarchical refinement for real-time edge-aware depth prediction\". ECCV 2018.<br>\n",
    "Zhang, Yinda, et al. (Google / PerceptiveIO) \"Activestereonet: end-to-end self-supervised learning for active stereo systems\". ECCV 2018.<br>\n",
    "<br>\n",
    "Training data is:<br>\n",
    "Mayer, N. et al. (Thomas Brox, University of Freiburg) \"A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation\". CVPR 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import generator as gen\n",
    "import os, sys\n",
    "import matplotlib as mp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from model import stereonet\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "#device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters and Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For inference ###\n",
    "\n",
    "# path to input \n",
    "inference_path          = 'inputs'\n",
    "\n",
    "# path to save\n",
    "save_path_depth         = 'outputs'\n",
    "save_path_disparity     = 'outputs'\n",
    "save_path_invalidation  = 'outputs'\n",
    "\n",
    "# scale factor for output\n",
    "depth_scale             = 1\n",
    "disparity_scale         = 256\n",
    "invalidation_scale      = 1024\n",
    "\n",
    "disp_min = 0\n",
    "disp_max = 255\n",
    "\n",
    "full_w = 960\n",
    "full_h = 540\n",
    "resolution = (full_h,full_w)\n",
    "\n",
    "# checkpoint to load\n",
    "# checkpoint_path         = './checkpoints/training_low_lr_2e-06_step_144755val_99.ckpt'\n",
    "\n",
    "is_from_beginning = True\n",
    "n_batch = 1\n",
    "n_views = 1\n",
    "is_training = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_every = 1\n",
    "sanity_check=True\n",
    "path_to_left_rgb = '/ben/kgx_nfs/data/external/sceneflow/frames_cleanpass/35mm_focallength/scene_forwards/slow/left/'\n",
    "path_to_right_rgb = '/ben/kgx_nfs/data/external/sceneflow/frames_cleanpass/35mm_focallength/scene_forwards/slow/right'\n",
    "left_rgb_names_train = [os.path.join(path_to_left_rgb,each_name) for each_name in os.listdir(path_to_left_rgb)][0::n_every]\n",
    "right_rgb_names_train = [os.path.join(path_to_right_rgb,each_name) for each_name in os.listdir(path_to_right_rgb)][0::n_every]\n",
    "\n",
    "path_to_disparity = '/ben/kgx_nfs/data/external/sceneflow/disparity/35mm_focallength/scene_forwards/slow/left'\n",
    "disparity_names_train = [os.path.join(path_to_disparity,each_name) for each_name in os.listdir(path_to_disparity)][0::n_every]\n",
    "\n",
    "left_rgb_names_train.sort()\n",
    "right_rgb_names_train.sort()\n",
    "disparity_names_train.sort()\n",
    "\n",
    "print(\"sanity check started.\")\n",
    "n_train_data = len(left_rgb_names_train)\n",
    "\n",
    "assert len(left_rgb_names_train) == len(right_rgb_names_train) == len(disparity_names_train), \"Error : number of files doesn't match\"\n",
    "\n",
    "for idx in range(n_train_data):\n",
    "\n",
    "    left_rgb = left_rgb_names_train[idx]\n",
    "    right_rgb = right_rgb_names_train[idx]\n",
    "    disparity = disparity_names_train[idx]\n",
    "\n",
    "    assert left_rgb.split('/')[-1].split('.')[-2] == right_rgb.split('/')[-1].split('.')[-2] == disparity.split('/')[-1].split('.')[-2],\"Error : wrong file name match\"\n",
    "\n",
    "    if idx % 500 == 0:\n",
    "        print(idx,\"out of\",n_train_data,\"completed\")\n",
    "\n",
    "print(\"sanity check finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training generator\n",
    "training_generator = iter(gen.TrainingGeneratorStereoNet(\\\n",
    "    left_rgb_names_train, right_rgb_names_train, disparity_names_train))\n",
    "generator_data_type = (tf.float32, tf.float32, tf.float32)\n",
    "training_set = tf.data.Dataset.from_generator(lambda: training_generator, generator_data_type)\n",
    "training_set = training_set.batch(n_batch)\n",
    "buffer_size = 1\n",
    "training_set = training_set.prefetch(buffer_size)\n",
    "# get training iterators\n",
    "training_iterator = training_set.make_initializable_iterator()\n",
    "# get data placeholders\n",
    "rgb_left_train, rgb_right_train, disparity_train = training_iterator.get_next()\n",
    "\n",
    "# Sizes at compile time\n",
    "rgb_left_train.set_shape(tf.TensorShape([n_batch, full_h, full_w, 3]))\n",
    "rgb_right_train.set_shape(tf.TensorShape([n_batch, full_h, full_w, 3]))\n",
    "disparity_train.set_shape(tf.TensorShape([n_batch, full_h, full_w, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the StereoNet and the InvalidationNet\n",
    "full_res_disparity_map, _, disparity_map_1_2, disparity_map_1_4, disparity_map_1_8 = stereonet(rgb_left_train,rgb_right_train, max_disp_lowres=18, is_training=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get disparity GT\n",
    "disparity_reference_1_8 = tf.image.resize_images(disparity_train,(int(math.ceil(float(full_h)/8)),int(full_w/8)),align_corners=True) / 8\n",
    "disparity_reference_1_4 = tf.image.resize_images(disparity_train,(int(full_h/4),int(full_w/4)),align_corners=True) / 4\n",
    "disparity_reference_1_2 = tf.image.resize_images(disparity_train,(int(full_h/2),int(full_w/2)),align_corners=True) / 2\n",
    "disparity_reference_1_1 = disparity_train\n",
    "\n",
    "disparity_1_8 = disparity_map_1_8\n",
    "disparity_1_4 = disparity_map_1_4\n",
    "disparity_1_2 = disparity_map_1_2\n",
    "disparity_1_1 = full_res_disparity_map\n",
    "\n",
    "#def barron_loss(x, a, c, e=1e-5):\n",
    "#    b = tf.abs(2.-a) + e\n",
    "#    d = tf.where(tf.greater_equal(a, 0.), a+e, a-e)\n",
    "#    return b/d * (tf.pow(tf.square(x/c)/b+1., 0.5 * d)-1.)\n",
    "\n",
    "#alpha = 1.0\n",
    "#c     = 2.0\n",
    "\n",
    "def barron_spec(x):    \n",
    "    return tf.sqrt(tf.square(x/2.0)+1.)-1.\n",
    "\n",
    "# normalization parameters for disparities\n",
    "disp_max_1_8 = tf.reduce_max(disparity_reference_1_8)\n",
    "disp_max_1_4 = tf.reduce_max(disparity_reference_1_4)\n",
    "disp_max_1_2 = tf.reduce_max(disparity_reference_1_2)\n",
    "disp_max_1_1 = tf.reduce_max(disparity_reference_1_1)\n",
    "disp_max_const = 1000.\n",
    "\n",
    "#diff_1_8 = (disparity_1_8 - disparity_reference_1_8) / disp_max_const\n",
    "#diff_1_4 = (disparity_1_4 - disparity_reference_1_4) / disp_max_const\n",
    "#diff_1_2 = (disparity_1_2 - disparity_reference_1_2) / disp_max_const\n",
    "#diff_1_1 = (disparity_1_1 - disparity_reference_1_1) / disp_max_const\n",
    "\n",
    "diff_1_8 = (disparity_1_8 - disparity_reference_1_8)\n",
    "diff_1_4 = (disparity_1_4 - disparity_reference_1_4)\n",
    "diff_1_2 = (disparity_1_2 - disparity_reference_1_2)\n",
    "diff_1_1 = (disparity_1_1 - disparity_reference_1_1)\n",
    "\n",
    "# get pixel count to normalize loss contribution on every level\n",
    "pixels_1_8 = int(math.ceil(float(full_h)/8)) * int(full_w/8)\n",
    "pixels_1_4 = int(full_h/4) * int(full_w/4)\n",
    "pixels_1_2 = int(full_h/2) * int(full_w/2)\n",
    "pixels_1_1 = int(full_h) * int(full_w)\n",
    "\n",
    "#loss_1_8 = tf.reduce_sum(barron_spec(diff_1_8)) / pixels_1_8 \n",
    "#loss_1_4 = tf.reduce_sum(barron_spec(diff_1_4)) / pixels_1_4\n",
    "#loss_1_2 = tf.reduce_sum(barron_spec(diff_1_2)) / pixels_1_2\n",
    "#loss_1_1 = tf.reduce_sum(barron_spec(diff_1_1)) / pixels_1_1\n",
    "\n",
    "loss_1_8 = tf.reduce_sum(barron_spec(diff_1_8))\n",
    "loss_1_4 = tf.reduce_sum(barron_spec(diff_1_4))\n",
    "loss_1_2 = tf.reduce_sum(barron_spec(diff_1_2))\n",
    "loss_1_1 = tf.reduce_sum(barron_spec(diff_1_1))\n",
    "\n",
    "#loss_1_8 = tf.reduce_sum(tf.square(disparity_1_8 - disparity_reference_1_8))\n",
    "#loss_1_4 = tf.reduce_sum(tf.square(disparity_1_4 - disparity_reference_1_4))\n",
    "#loss_1_2 = tf.reduce_sum(tf.square(disparity_1_2 - disparity_reference_1_2))\n",
    "#loss_1_1 = tf.reduce_sum(tf.square(disparity_1_1 - disparity_reference_1_1))\n",
    "\n",
    "loss = loss_1_8 + loss_1_4 + loss_1_2 + loss_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializors\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss=loss)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "train_summary_op = tf.summary.scalar(\"train_loss\",loss)\n",
    "writer = tf.summary.FileWriter(\"./logs\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(training_iterator.initializer)\n",
    "train_init_op = training_iterator.make_initializer(training_set)\n",
    "sess.run(train_init_op)\n",
    "#img_left = sess.run(rgb_left_train)\n",
    "#print img_left.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_from_beginning:\n",
    "    lr = 1e-4\n",
    "    step = 0\n",
    "    val_step = 0\n",
    "    losses = np.zeros((1,3))\n",
    "else:\n",
    "    saver1 = tf.train.Saver(var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))\n",
    "    saver1.restore(sess, './checkpoints/stereoNet_testrun_9.69773729788e-07_step_88000val_0.ckpt')\n",
    "    lr = 9.69773729788e-07\n",
    "    step = 88000\n",
    "    val_step = 0\n",
    "    #9.69773729788e-07_step_88000val_0.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "n_iter = 200000\n",
    "show_all_n_every_step = 10000\n",
    "save_n_every_step = 2000\n",
    "show_n_every_step = 100\n",
    "show_n_losses = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(tuple_of_images,tuple_of_titles,statement,idx_in_batch=0):\n",
    "    print(statement)\n",
    "    n_images = len(tuple_of_images)\n",
    "    \n",
    "    for each_idx in range(n_images):\n",
    "        \n",
    "        plt.figure(figsize=(15,60))\n",
    "        plt.title(tuple_of_titles[each_idx])\n",
    "        plt.axis('off')\n",
    "        if n_images == 1:\n",
    "            each_image = tuple_of_images.squeeze()\n",
    "        else:\n",
    "            each_image = tuple_of_images[each_idx][idx_in_batch].squeeze()\n",
    "        plt.imshow(each_image)\n",
    "        #plt.imshow(each_image,cmap='gray')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_epoch in range(n_epoch):\n",
    "    for each_iter in range(n_iter):\n",
    "        \n",
    "        run_list = [train_op,\n",
    "                    train_summary_op,\n",
    "                    loss, loss_1_8, loss_1_1,\n",
    "                    rgb_left_train, disparity_reference_1_1,\n",
    "                    disparity_1_8, disparity_1_4, disparity_1_2, disparity_1_1\n",
    "                   ]\n",
    "        \n",
    "        output = sess.run(run_list, feed_dict={learning_rate:lr})\n",
    "        \n",
    "        train_summary = output[1]\n",
    "        loss_out, loss_1_8_out, loss_1_1_out = output[2:5]\n",
    "        rgb_out, disparity_out = output[5:7]\n",
    "        disparity_1_8_out, disparity_1_4_out, disparity_1_2_out, disparity_1_1_out = output[7:11]\n",
    "                \n",
    "        writer.add_summary(train_summary,int(step))\n",
    "        if step % show_n_losses == 0:\n",
    "            print \"step :\",step,\"loss :\",loss_out, \" (\",loss_1_8_out,\"+\",loss_1_1_out,\" )\"\n",
    "            #print np.amin(disparity_1_8_out), np.amax(disparity_1_8_out)\n",
    "            #print np.amin(disparity_1_1_out), np.amax(disparity_1_1_out)\n",
    "            losses = np.append(losses, [[loss_out, loss_1_8_out, loss_1_1_out]], axis=0)\n",
    "    \n",
    "        if step != 0 and step % save_n_every_step == 0:\n",
    "            lr *= 0.9\n",
    "            saver = tf.train.Saver(var_list = tf.global_variables())\n",
    "            save_path = saver.save(sess,\"checkpoints/stereoNet_testrun_\" + str(lr) + \"_step_\" + str(step) + \"val_\" + str(val_step) + '.ckpt')\n",
    "        \n",
    "        if step != 0 and step % show_n_every_step == 0:\n",
    "            #print disparity_1_8_out, disparity_1_4_out, disparity_1_2_out, disparity_1_1_out\n",
    "            display_images((rgb_out,disparity_out,\n",
    "                                 disparity_1_8_out\n",
    "                                ),\n",
    "                                ('original img','disparity_gt',\n",
    "                                 'disparity_raw 1/8'\n",
    "                                ),\n",
    "                                'testrun')\n",
    "            \n",
    "            mp.pyplot.plot(losses[1:,1])\n",
    "            mp.pyplot.legend(['loss_1_8_out'])\n",
    "            fig = plt.figure()\n",
    "            mp.pyplot.plot(losses[1:,2])\n",
    "            mp.pyplot.legend(['loss_1_1_out'])\n",
    "            plt.show()\n",
    "            \n",
    "        if step != 0 and step % show_all_n_every_step == 0:\n",
    "            #print disparity_1_8_out, disparity_1_4_out, disparity_1_2_out, disparity_1_1_out\n",
    "            display_images((rgb_out,disparity_out,\n",
    "                                 disparity_1_8_out,\n",
    "                                 disparity_1_4_out,\n",
    "                                 disparity_1_2_out,\n",
    "                                 disparity_1_1_out\n",
    "                                ),\n",
    "                                ('original img','disparity_gt',\n",
    "                                 'disparity_raw 1/8',\n",
    "                                 'disparity 1/4',\n",
    "                                 'disparity 1/2',\n",
    "                                 'disparity 1/1'\n",
    "                                ),\n",
    "                                'testrun')\n",
    "        step += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.display_images((rgb_out,disparity_out,\n",
    "                                 disparity_1_8_out,\n",
    "                                 disparity_1_4_out,\n",
    "                                 disparity_1_2_out,\n",
    "                                 disparity_1_1_out\n",
    "                                ),\n",
    "                                ('original img','disparity_gt',\n",
    "                                 'disparity_raw 1/8',\n",
    "                                 'disparity 1/4',\n",
    "                                 'disparity 1/2',\n",
    "                                 'disparity 1/1'\n",
    "                                ),\n",
    "                                'testrun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
